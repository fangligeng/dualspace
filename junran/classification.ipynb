{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv \n",
    "import sys \n",
    "from collections import Counter\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feats(ffs, direc=\"train\", global_feat_dict=None):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      ffs are a list of feature-functions.\n",
    "      direc is a directory containing xml files (expected to be train or test).\n",
    "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
    "      should only be provided when extracting features from test data, so that \n",
    "      the columns of the test matrix align correctly.\n",
    "\n",
    "    returns: \n",
    "      a sparse design matrix, a dict mapping features to column-numbers,\n",
    "      a vector of target classes, and a list of system-call-history ids in order \n",
    "      of their rows in the design matrix.\n",
    "      \n",
    "      Note: the vector of target classes returned will contain the true indices of the\n",
    "      target classes on the training data, but will contain only -1's on the test\n",
    "      data\n",
    "    \"\"\"\n",
    "    fds = [] # list of feature dicts\n",
    "    classes = []\n",
    "    ids = [] \n",
    "    for datafile in os.listdir(direc):\n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str,clazz = datafile.split('.')[:2]\n",
    "        ids.append(id_str)\n",
    "        # add target class if this is training data\n",
    "        try:\n",
    "            classes.append(util.malware_classes.index(clazz))\n",
    "        except ValueError:\n",
    "            # we should only fail to find the label in our list of malware classes\n",
    "            # if this is test data, which always has an \"X\" label\n",
    "            assert clazz == \"X\"\n",
    "            classes.append(-1)\n",
    "        rowfd = {}\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        # accumulate features\n",
    "        [rowfd.update(ff(tree)) for ff in ffs]\n",
    "        fds.append(rowfd)\n",
    "    \n",
    "    X,feat_dict = make_design_mat(fds,global_feat_dict)\n",
    "    return X, feat_dict, np.array(classes), ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_design_mat(fds, global_feat_dict=None):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "      fds is a list of feature dicts (one for each row).\n",
    "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
    "      should only be provided when extracting features from test data, so that \n",
    "      the columns of the test matrix align correctly.\n",
    "       \n",
    "    returns: \n",
    "        a sparse NxD design matrix, where N == len(fds) and D is the number of\n",
    "        the union of features defined in any of the fds \n",
    "    \"\"\"\n",
    "    if global_feat_dict is None:\n",
    "        all_feats = set()\n",
    "        [all_feats.update(fd.keys()) for fd in fds]\n",
    "        feat_dict = dict([(feat, i) for i, feat in enumerate(sorted(all_feats))])\n",
    "    else:\n",
    "        feat_dict = global_feat_dict\n",
    "    \n",
    "    cols = []\n",
    "    rows = []\n",
    "    data = []        \n",
    "    for i in xrange(len(fds)):\n",
    "        temp_cols = []\n",
    "        temp_data = []\n",
    "        for feat,val in fds[i].iteritems():\n",
    "            try:\n",
    "                # update temp_cols iff update temp_data\n",
    "                temp_cols.append(feat_dict[feat])\n",
    "                temp_data.append(val)\n",
    "            except KeyError as ex:\n",
    "                if global_feat_dict is not None:\n",
    "                    pass  # new feature in test data; nbd\n",
    "                else:\n",
    "                    raise ex\n",
    "\n",
    "        # all fd's features in the same row\n",
    "        k = len(temp_cols)\n",
    "        cols.extend(temp_cols)\n",
    "        data.extend(temp_data)\n",
    "        rows.extend([i]*k)\n",
    "\n",
    "    assert len(cols) == len(rows) and len(rows) == len(data)\n",
    "   \n",
    "\n",
    "    X = sparse.csr_matrix((np.array(data),\n",
    "                   (np.array(rows), np.array(cols))),\n",
    "                   shape=(len(fds), len(feat_dict)))\n",
    "    return X, feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_call_4_grams_feats(tree):\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    first = False # is this the first system call\n",
    "    first_call = \"\"\n",
    "    second = False\n",
    "    second_call = \"\"\n",
    "    third = False\n",
    "    third_call = \"\"\n",
    "    call_counter = 0\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "            first = True\n",
    "            second = False\n",
    "            third = False\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "            first = False\n",
    "            second = False\n",
    "            third = False\n",
    "        elif in_all_section:\n",
    "            call_counter += 1\n",
    "            if first:\n",
    "                first_call = el.tag\n",
    "                first = False\n",
    "                second = True\n",
    "                third = False\n",
    "            elif second:\n",
    "                second_call = el.tag\n",
    "                second = False\n",
    "                third = False\n",
    "            elif third:\n",
    "                third_call = el.tag\n",
    "                third = False\n",
    "            else:\n",
    "                c[first_call+'-'+second_call+'-'+third_call+'-'+el.tag] += 1\n",
    "                first_call = second_call\n",
    "                second_call = third_call\n",
    "                third_call = el.tag\n",
    "                \n",
    "    for k, v in c.items():\n",
    "        c[k] = v / float(call_counter)\n",
    "    c['num_system_calls'] = call_counter\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_call_2_grams_feats(tree):\n",
    "    c = Counter()\n",
    "    in_all_section = False\n",
    "    first = False # is this the first system call\n",
    "    first_call = \"\"\n",
    "    call_counter = 0\n",
    "    for el in tree.iter():\n",
    "        # ignore everything outside the \"all_section\" element\n",
    "        if el.tag == \"all_section\" and not in_all_section:\n",
    "            in_all_section = True\n",
    "            first = True\n",
    "        elif el.tag == \"all_section\" and in_all_section:\n",
    "            in_all_section = False\n",
    "            first = False\n",
    "        elif in_all_section:\n",
    "            call_counter += 1\n",
    "            if first:\n",
    "                if el.tag == \"load_dll\" and \"filename_hash\" in el.attrib:\n",
    "                    first_call = el.attrib[\"filename_hash\"]\n",
    "                else:\n",
    "                    first_call = el.tag\n",
    "                first = False\n",
    "            else:\n",
    "                sys_call = \"\"\n",
    "                if el.tag == \"load_dll\" and \"filename_hash\" in el.attrib:\n",
    "                    sys_call = el.attrib[\"filename_hash\"]\n",
    "                else:\n",
    "                    sys_call = el.tag\n",
    "                c[first_call+'-'+sys_call] += 1\n",
    "                first_call = sys_call\n",
    "                \n",
    "    for k, v in c.items():\n",
    "        c[k] = v / float(call_counter)\n",
    "    c['num_system_calls'] = call_counter\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_submission(file_to_reorder, newfile_name = \"experiment_results.csv\"):\n",
    "    # READ IN KEYS IN CORRECT ORDER AS LIST\n",
    "    with open('keys.csv','r') as f:\n",
    "        keyreader = csv.reader(f)\n",
    "        keys = [key[0] for key in keyreader]\n",
    "\n",
    "    # READ IN ALL PREDICTIONS, REGARDLESS OF ORDER\n",
    "    with open(file_to_reorder) as f:\n",
    "        oldfile_reader = csv.reader(f)\n",
    "        D = {}\n",
    "        for i,row in enumerate(oldfile_reader):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            _id, pred = row \n",
    "            D[_id] = pred\n",
    "\n",
    "    # WRITE PREDICTIONS IN NEW ORDER\n",
    "    with open(newfile_name,'wb') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(('Id','Prediction'))\n",
    "        for key in keys:\n",
    "            writer.writerow((key,D[key]))\n",
    "\n",
    "    print(\"\".join([\"Reordered \", file_to_reorder,\" and wrote to \", newfile_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#\n",
    "#  Below is main function\n",
    "#\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../train/sub_train\"\n",
    "test_dir = \"../train/sub_test\"\n",
    "submission_dir = \"../test\"\n",
    "outputfile = \"experiment_predictions.csv\"  # feel free to change this or take it as an argument\n",
    "ffs = [system_call_2_grams_feats] # TODO put the names of the feature functions you've defined above in this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting training features...\n"
     ]
    }
   ],
   "source": [
    "# extract features\n",
    "print \"extracting training features...\"\n",
    "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "\n",
    "y_train = np.zeros((len(t_train),len(util.malware_classes)))\n",
    "y_train[np.arange(len(t_train)), t_train] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting test features...\n"
     ]
    }
   ],
   "source": [
    "print \"extracting test features...\"\n",
    "X_test,_,t_test,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
    "\n",
    "y_test = np.zeros((len(t_test),len(util.malware_classes)))\n",
    "y_test[np.arange(len(t_test)), t_test] = 1\n",
    "\n",
    "# print y_train.shape\n",
    "# print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting submission features...\n"
     ]
    }
   ],
   "source": [
    "print \"extracting submission features...\"\n",
    "X_submission,_,t_submission,submission_ids = extract_feats(ffs, submission_dir, global_feat_dict=global_feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth:  10 , n_estimators:  10\n",
      "train:  0.6074014481094127 , test:  0.6116666666666667\n",
      "max_depth:  10 , n_estimators:  20\n",
      "train:  0.6186645213193885 , test:  0.63\n",
      "max_depth:  10 , n_estimators:  30\n",
      "train:  0.5543041029766693 , test:  0.5766666666666667\n",
      "max_depth:  10 , n_estimators:  40\n",
      "train:  0.6230893000804505 , test:  0.625\n",
      "max_depth:  10 , n_estimators:  50\n",
      "train:  0.6263073209975865 , test:  0.6266666666666667\n",
      "max_depth:  10 , n_estimators:  60\n",
      "train:  0.6210780370072405 , test:  0.625\n",
      "max_depth:  10 , n_estimators:  70\n",
      "train:  0.6082059533386966 , test:  0.6183333333333333\n",
      "max_depth:  10 , n_estimators:  80\n",
      "train:  0.6178600160901045 , test:  0.6166666666666667\n",
      "max_depth:  10 , n_estimators:  90\n",
      "train:  0.3077232502011263 , test:  0.34\n",
      "max_depth:  15 , n_estimators:  10\n",
      "train:  0.6822204344328238 , test:  0.675\n",
      "max_depth:  15 , n_estimators:  20\n",
      "train:  0.672566371681416 , test:  0.6733333333333333\n",
      "max_depth:  15 , n_estimators:  30\n",
      "train:  0.6910699919549477 , test:  0.6766666666666666\n",
      "max_depth:  15 , n_estimators:  40\n",
      "train:  0.6781979082864039 , test:  0.6683333333333333\n",
      "max_depth:  15 , n_estimators:  50\n",
      "train:  0.6846339501206757 , test:  0.6783333333333333\n",
      "max_depth:  15 , n_estimators:  60\n",
      "train:  0.6874497184231697 , test:  0.6766666666666666\n",
      "max_depth:  15 , n_estimators:  70\n",
      "train:  0.6810136765888978 , test:  0.6766666666666666\n",
      "max_depth:  15 , n_estimators:  80\n",
      "train:  0.6850362027353177 , test:  0.6766666666666666\n",
      "max_depth:  15 , n_estimators:  90\n",
      "train:  0.6862429605792437 , test:  0.6783333333333333\n",
      "max_depth:  20 , n_estimators:  10\n",
      "train:  0.7582461786001609 , test:  0.6916666666666667\n",
      "max_depth:  20 , n_estimators:  20\n",
      "train:  0.7441673370876911 , test:  0.69\n",
      "max_depth:  20 , n_estimators:  30\n",
      "train:  0.7614641995172968 , test:  0.7083333333333334\n",
      "max_depth:  20 , n_estimators:  40\n",
      "train:  0.7244569589702333 , test:  0.6883333333333334\n",
      "max_depth:  20 , n_estimators:  50\n",
      "train:  0.7502011263073209 , test:  0.6883333333333334\n",
      "max_depth:  20 , n_estimators:  60\n",
      "train:  0.7493966210780371 , test:  0.6983333333333334\n",
      "max_depth:  20 , n_estimators:  70\n",
      "train:  0.7365245374094932 , test:  0.6916666666666667\n",
      "max_depth:  20 , n_estimators:  80\n",
      "train:  0.7240547063555913 , test:  0.6816666666666666\n",
      "max_depth:  20 , n_estimators:  90\n",
      "train:  0.7526146419951729 , test:  0.7016666666666667\n",
      "max_depth:  25 , n_estimators:  10\n",
      "train:  0.833065164923572 , test:  0.7466666666666667\n",
      "max_depth:  25 , n_estimators:  20\n",
      "train:  0.8632341110217217 , test:  0.7616666666666667\n",
      "max_depth:  25 , n_estimators:  30\n",
      "train:  0.833869670152856 , test:  0.7316666666666667\n",
      "max_depth:  25 , n_estimators:  40\n",
      "train:  0.8238133547868061 , test:  0.7266666666666667\n",
      "max_depth:  25 , n_estimators:  50\n",
      "train:  0.8374899436846339 , test:  0.7383333333333333\n",
      "max_depth:  25 , n_estimators:  60\n",
      "train:  0.828238133547868 , test:  0.7283333333333334\n",
      "max_depth:  25 , n_estimators:  70\n",
      "train:  0.827031375703942 , test:  0.7316666666666667\n",
      "max_depth:  25 , n_estimators:  80\n",
      "train:  0.8169750603378922 , test:  0.7266666666666667\n",
      "max_depth:  25 , n_estimators:  90\n",
      "train:  0.8358809332260659 , test:  0.7283333333333334\n",
      "max_depth:  30 , n_estimators:  10\n",
      "train:  0.8881737731295254 , test:  0.7816666666666666\n",
      "max_depth:  30 , n_estimators:  20\n",
      "train:  0.914320193081255 , test:  0.7833333333333333\n",
      "max_depth:  30 , n_estimators:  30\n",
      "train:  0.9070796460176991 , test:  0.785\n",
      "max_depth:  30 , n_estimators:  40\n",
      "train:  0.9026548672566371 , test:  0.7766666666666666\n",
      "max_depth:  30 , n_estimators:  50\n",
      "train:  0.9094931617055511 , test:  0.79\n",
      "max_depth:  30 , n_estimators:  60\n",
      "train:  0.9090909090909091 , test:  0.79\n",
      "max_depth:  30 , n_estimators:  70\n",
      "train:  0.9074818986323411 , test:  0.7766666666666666\n",
      "max_depth:  30 , n_estimators:  80\n",
      "train:  0.9207562349155269 , test:  0.7933333333333333\n",
      "max_depth:  30 , n_estimators:  90\n",
      "train:  0.9239742558326629 , test:  0.795\n",
      "max_depth:  35 , n_estimators:  10\n",
      "train:  0.9259855189058729 , test:  0.81\n",
      "max_depth:  35 , n_estimators:  20\n",
      "train:  0.9263877715205149 , test:  0.7966666666666666\n",
      "max_depth:  35 , n_estimators:  30\n",
      "train:  0.9352373290426388 , test:  0.81\n",
      "max_depth:  35 , n_estimators:  40\n",
      "train:  0.9408688656476267 , test:  0.8166666666666667\n",
      "max_depth:  35 , n_estimators:  50\n",
      "train:  0.9469026548672567 , test:  0.8183333333333334\n",
      "max_depth:  35 , n_estimators:  60\n",
      "train:  0.9509251810136766 , test:  0.815\n",
      "max_depth:  35 , n_estimators:  70\n",
      "train:  0.9452936444086887 , test:  0.8116666666666666\n",
      "max_depth:  35 , n_estimators:  80\n",
      "train:  0.9420756234915527 , test:  0.8133333333333334\n",
      "max_depth:  35 , n_estimators:  90\n",
      "train:  0.9452936444086887 , test:  0.8116666666666666\n",
      "max_depth:  40 , n_estimators:  10\n",
      "train:  0.9356395816572808 , test:  0.8233333333333334\n",
      "max_depth:  40 , n_estimators:  20\n",
      "train:  0.9473049074818987 , test:  0.82\n",
      "max_depth:  40 , n_estimators:  30\n",
      "train:  0.9529364440868866 , test:  0.8216666666666667\n",
      "max_depth:  40 , n_estimators:  40\n",
      "train:  0.9557522123893806 , test:  0.83\n",
      "max_depth:  40 , n_estimators:  50\n",
      "train:  0.9565567176186646 , test:  0.8233333333333334\n",
      "max_depth:  40 , n_estimators:  60\n",
      "train:  0.9541432019308126 , test:  0.8166666666666667\n",
      "max_depth:  40 , n_estimators:  70\n",
      "train:  0.9589702333065165 , test:  0.82\n",
      "max_depth:  40 , n_estimators:  80\n",
      "train:  0.9605792437650845 , test:  0.8283333333333334\n",
      "max_depth:  40 , n_estimators:  90\n",
      "train:  0.9581657280772325 , test:  0.8166666666666667\n",
      "max_depth:  45 , n_estimators:  10\n",
      "train:  0.9561544650040226 , test:  0.8283333333333334\n",
      "max_depth:  45 , n_estimators:  20\n",
      "train:  0.9577634754625906 , test:  0.8283333333333334\n",
      "max_depth:  45 , n_estimators:  30\n",
      "train:  0.9569589702333066 , test:  0.8233333333333334\n",
      "max_depth:  45 , n_estimators:  40\n",
      "train:  0.9646017699115044 , test:  0.8333333333333334\n",
      "max_depth:  45 , n_estimators:  50\n",
      "train:  0.9637972646822205 , test:  0.8283333333333334\n",
      "max_depth:  45 , n_estimators:  60\n",
      "train:  0.9702333065164923 , test:  0.825\n",
      "max_depth:  45 , n_estimators:  70\n",
      "train:  0.9650040225261464 , test:  0.83\n",
      "max_depth:  45 , n_estimators:  80\n",
      "train:  0.9686242960579243 , test:  0.83\n",
      "max_depth:  45 , n_estimators:  90\n",
      "train:  0.9682220434432823 , test:  0.83\n",
      "max_depth:  50 , n_estimators:  10\n",
      "train:  0.9525341914722446 , test:  0.835\n",
      "max_depth:  50 , n_estimators:  20\n",
      "train:  0.9625905068382945 , test:  0.83\n",
      "max_depth:  50 , n_estimators:  30\n",
      "train:  0.9714400643604183 , test:  0.8316666666666667\n",
      "max_depth:  50 , n_estimators:  40\n",
      "train:  0.9702333065164923 , test:  0.8366666666666667\n",
      "max_depth:  50 , n_estimators:  50\n",
      "train:  0.9714400643604183 , test:  0.8383333333333334\n",
      "max_depth:  50 , n_estimators:  60\n",
      "train:  0.9714400643604183 , test:  0.8283333333333334\n",
      "max_depth:  50 , n_estimators:  70\n",
      "train:  0.9718423169750603 , test:  0.8433333333333334\n",
      "max_depth:  50 , n_estimators:  80\n",
      "train:  0.9754625905068383 , test:  0.8416666666666667\n",
      "max_depth:  50 , n_estimators:  90\n",
      "train:  0.9746580852775543 , test:  0.84\n",
      "max_depth:  55 , n_estimators:  10\n",
      "train:  0.9593724859211585 , test:  0.83\n",
      "max_depth:  55 , n_estimators:  20\n",
      "train:  0.9726468222043443 , test:  0.8316666666666667\n",
      "max_depth:  55 , n_estimators:  30\n",
      "train:  0.9730490748189863 , test:  0.845\n",
      "max_depth:  55 , n_estimators:  40\n",
      "train:  0.9730490748189863 , test:  0.84\n",
      "max_depth:  55 , n_estimators:  50\n",
      "train:  0.9734513274336283 , test:  0.8316666666666667\n",
      "max_depth:  55 , n_estimators:  60\n",
      "train:  0.9754625905068383 , test:  0.835\n",
      "max_depth:  55 , n_estimators:  70\n",
      "train:  0.9766693483507642 , test:  0.8383333333333334\n",
      "max_depth:  55 , n_estimators:  80\n",
      "train:  0.9774738535800482 , test:  0.835\n",
      "max_depth:  55 , n_estimators:  90\n",
      "train:  0.9766693483507642 , test:  0.8383333333333334\n",
      "max_depth:  60 , n_estimators:  10\n",
      "train:  0.9625905068382945 , test:  0.8216666666666667\n",
      "max_depth:  60 , n_estimators:  20\n",
      "train:  0.9714400643604183 , test:  0.835\n",
      "max_depth:  60 , n_estimators:  30\n",
      "train:  0.9754625905068383 , test:  0.8383333333333334\n",
      "max_depth:  60 , n_estimators:  40\n",
      "train:  0.9778761061946902 , test:  0.8433333333333334\n",
      "max_depth:  60 , n_estimators:  50\n",
      "train:  0.9786806114239742 , test:  0.8433333333333334\n",
      "max_depth:  60 , n_estimators:  60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.9790828640386162 , test:  0.8316666666666667\n",
      "max_depth:  60 , n_estimators:  70\n",
      "train:  0.9798873692679002 , test:  0.8416666666666667\n",
      "max_depth:  60 , n_estimators:  80\n",
      "train:  0.9774738535800482 , test:  0.8416666666666667\n",
      "max_depth:  60 , n_estimators:  90\n",
      "train:  0.9798873692679002 , test:  0.8416666666666667\n",
      "max_depth:  65 , n_estimators:  10\n",
      "train:  0.9617860016090105 , test:  0.8233333333333334\n",
      "max_depth:  65 , n_estimators:  20\n",
      "train:  0.9718423169750603 , test:  0.8316666666666667\n",
      "max_depth:  65 , n_estimators:  30\n",
      "train:  0.9758648431214803 , test:  0.8366666666666667\n",
      "max_depth:  65 , n_estimators:  40\n",
      "train:  0.9790828640386162 , test:  0.8483333333333334\n",
      "max_depth:  65 , n_estimators:  50\n",
      "train:  0.9782783588093322 , test:  0.8433333333333334\n",
      "max_depth:  65 , n_estimators:  60\n",
      "train:  0.9806918744971842 , test:  0.8416666666666667\n",
      "max_depth:  65 , n_estimators:  70\n",
      "train:  0.9802896218825422 , test:  0.84\n",
      "max_depth:  65 , n_estimators:  80\n",
      "train:  0.9806918744971842 , test:  0.8433333333333334\n",
      "max_depth:  65 , n_estimators:  90\n",
      "train:  0.9806918744971842 , test:  0.8366666666666667\n",
      "max_depth:  70 , n_estimators:  10\n",
      "train:  0.9625905068382945 , test:  0.8283333333333334\n",
      "max_depth:  70 , n_estimators:  20\n",
      "train:  0.9726468222043443 , test:  0.8416666666666667\n",
      "max_depth:  70 , n_estimators:  30\n",
      "train:  0.9758648431214803 , test:  0.835\n",
      "max_depth:  70 , n_estimators:  40\n",
      "train:  0.9782783588093322 , test:  0.8366666666666667\n",
      "max_depth:  70 , n_estimators:  50\n",
      "train:  0.9786806114239742 , test:  0.8433333333333334\n",
      "max_depth:  70 , n_estimators:  60\n",
      "train:  0.9806918744971842 , test:  0.8366666666666667\n",
      "max_depth:  70 , n_estimators:  70\n",
      "train:  0.9798873692679002 , test:  0.8416666666666667\n",
      "max_depth:  70 , n_estimators:  80\n",
      "train:  0.9806918744971842 , test:  0.8433333333333334\n",
      "max_depth:  70 , n_estimators:  90\n",
      "train:  0.9806918744971842 , test:  0.845\n",
      "max_depth:  75 , n_estimators:  10\n",
      "train:  0.9597747385358005 , test:  0.83\n",
      "max_depth:  75 , n_estimators:  20\n",
      "train:  0.9738535800482703 , test:  0.8383333333333334\n",
      "max_depth:  75 , n_estimators:  30\n",
      "train:  0.9766693483507642 , test:  0.8366666666666667\n",
      "max_depth:  75 , n_estimators:  40\n",
      "train:  0.9774738535800482 , test:  0.8316666666666667\n",
      "max_depth:  75 , n_estimators:  50\n",
      "train:  0.9790828640386162 , test:  0.8383333333333334\n",
      "max_depth:  75 , n_estimators:  60\n",
      "train:  0.9798873692679002 , test:  0.85\n",
      "max_depth:  75 , n_estimators:  70\n",
      "train:  0.9806918744971842 , test:  0.84\n",
      "max_depth:  75 , n_estimators:  80\n",
      "train:  0.9806918744971842 , test:  0.84\n",
      "max_depth:  75 , n_estimators:  90\n",
      "train:  0.9810941271118262 , test:  0.8466666666666667\n",
      "max_depth:  80 , n_estimators:  10\n",
      "train:  0.9601769911504425 , test:  0.8233333333333334\n",
      "max_depth:  80 , n_estimators:  20\n",
      "train:  0.9742558326629123 , test:  0.8416666666666667\n",
      "max_depth:  80 , n_estimators:  30\n",
      "train:  0.9782783588093322 , test:  0.8416666666666667\n",
      "max_depth:  80 , n_estimators:  40\n",
      "train:  0.9798873692679002 , test:  0.8466666666666667\n",
      "max_depth:  80 , n_estimators:  50\n",
      "train:  0.9794851166532582 , test:  0.845\n",
      "max_depth:  80 , n_estimators:  60\n",
      "train:  0.9794851166532582 , test:  0.8433333333333334\n",
      "max_depth:  80 , n_estimators:  70\n",
      "train:  0.9798873692679002 , test:  0.845\n",
      "max_depth:  80 , n_estimators:  80\n",
      "train:  0.9806918744971842 , test:  0.845\n",
      "max_depth:  80 , n_estimators:  90\n",
      "train:  0.9810941271118262 , test:  0.8383333333333334\n",
      "max_depth:  85 , n_estimators:  10\n",
      "train:  0.9605792437650845 , test:  0.8266666666666667\n",
      "max_depth:  85 , n_estimators:  20\n",
      "train:  0.9758648431214803 , test:  0.8283333333333334\n",
      "max_depth:  85 , n_estimators:  30\n",
      "train:  0.9774738535800482 , test:  0.8483333333333334\n",
      "max_depth:  85 , n_estimators:  40\n",
      "train:  0.9774738535800482 , test:  0.8333333333333334\n",
      "max_depth:  85 , n_estimators:  50\n",
      "train:  0.9794851166532582 , test:  0.8483333333333334\n",
      "max_depth:  85 , n_estimators:  60\n",
      "train:  0.9790828640386162 , test:  0.8466666666666667\n",
      "max_depth:  85 , n_estimators:  70\n",
      "train:  0.9802896218825422 , test:  0.8483333333333334\n",
      "max_depth:  85 , n_estimators:  80\n",
      "train:  0.9798873692679002 , test:  0.8383333333333334\n",
      "max_depth:  85 , n_estimators:  90\n",
      "train:  0.9806918744971842 , test:  0.8366666666666667\n",
      "max_depth:  90 , n_estimators:  10\n",
      "train:  0.9629927594529365 , test:  0.8333333333333334\n",
      "max_depth:  90 , n_estimators:  20\n",
      "train:  0.9730490748189863 , test:  0.8383333333333334\n",
      "max_depth:  90 , n_estimators:  30\n",
      "train:  0.9786806114239742 , test:  0.84\n",
      "max_depth:  90 , n_estimators:  40\n",
      "train:  0.9794851166532582 , test:  0.845\n",
      "max_depth:  90 , n_estimators:  50\n",
      "train:  0.9806918744971842 , test:  0.845\n",
      "max_depth:  90 , n_estimators:  60\n",
      "train:  0.9802896218825422 , test:  0.8466666666666667\n",
      "max_depth:  90 , n_estimators:  70\n",
      "train:  0.9802896218825422 , test:  0.8383333333333334\n",
      "max_depth:  90 , n_estimators:  80\n",
      "train:  0.9802896218825422 , test:  0.8416666666666667\n",
      "max_depth:  90 , n_estimators:  90\n",
      "train:  0.9790828640386162 , test:  0.84\n",
      "max_depth:  95 , n_estimators:  10\n",
      "train:  0.9633950120675785 , test:  0.8216666666666667\n",
      "max_depth:  95 , n_estimators:  20\n",
      "train:  0.9718423169750603 , test:  0.8366666666666667\n",
      "max_depth:  95 , n_estimators:  30\n",
      "train:  0.9774738535800482 , test:  0.8466666666666667\n",
      "max_depth:  95 , n_estimators:  40\n",
      "train:  0.9786806114239742 , test:  0.8416666666666667\n",
      "max_depth:  95 , n_estimators:  50\n",
      "train:  0.9802896218825422 , test:  0.845\n",
      "max_depth:  95 , n_estimators:  60\n",
      "train:  0.9806918744971842 , test:  0.845\n",
      "max_depth:  95 , n_estimators:  70\n",
      "train:  0.9802896218825422 , test:  0.8433333333333334\n",
      "max_depth:  95 , n_estimators:  80\n",
      "train:  0.9806918744971842 , test:  0.84\n",
      "max_depth:  95 , n_estimators:  90\n",
      "train:  0.9798873692679002 , test:  0.84\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 100, 5):\n",
    "    for j in range(10, 100, 10):\n",
    "        RF = RandomForestClassifier(class_weight=\"balanced\", n_jobs=-1, max_depth=i, n_estimators=j)\n",
    "        RF.fit(X_train, y_train)\n",
    "        print 'max_depth: ', i, ', n_estimators: ', j\n",
    "        print 'train: ', RF.score(X_train, y_train), ', test: ', RF.score(X_test, y_test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=50, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(class_weight=\"balanced\", n_jobs=-1, max_depth=50, n_estimators=10)\n",
    "# print np.mean(cross_val_score(RF, X_train, y_train, cv=5))\n",
    "RF.fit(X_train, y_train)\n",
    "# print RF.n_features_\n",
    "# print RF.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = RF.predict(X_submission)\n",
    "# print preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions...\n",
      "writing predictions...\n",
      "Reordered experiment_predictions.csv and wrote to Bigrams_randomforest_results.csv\n"
     ]
    }
   ],
   "source": [
    "# TODO make predictions on text data and write them out\n",
    "print \"making predictions...\"\n",
    "results = np.argmax(preds, axis=1)\n",
    "\n",
    "print \"writing predictions...\"\n",
    "util.write_predictions(results, submission_ids, outputfile)\n",
    "\n",
    "reorder_submission(outputfile, \"Bigrams_randomforest_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
