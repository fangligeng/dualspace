{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanxu/anaconda2/envs/my-rdkit-env/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv \n",
    "import sys \n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from collections import Counter\n",
    "import xgboost as xgb\n",
    "\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import sys \n",
    "\n",
    "def reorder_submission(file_to_reorder, newfile_name = \"experiment_results.csv\"):\n",
    "    # READ IN KEYS IN CORRECT ORDER AS LIST\n",
    "    with open('keys.csv','r') as f:\n",
    "        keyreader = csv.reader(f)\n",
    "        keys = [key[0] for key in keyreader]\n",
    "\n",
    "    # READ IN ALL PREDICTIONS, REGARDLESS OF ORDER\n",
    "    with open(file_to_reorder) as f:\n",
    "        oldfile_reader = csv.reader(f)\n",
    "        D = {}\n",
    "        for i,row in enumerate(oldfile_reader):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            _id, pred = row \n",
    "            D[_id] = pred\n",
    "\n",
    "    # WRITE PREDICTIONS IN NEW ORDER\n",
    "    with open(newfile_name,'wb') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(('Id','Prediction'))\n",
    "        for key in keys:\n",
    "            writer.writerow((key,D[key]))\n",
    "\n",
    "    print(\"\".join([\"Reordered \", file_to_reorder,\" and wrote to \", newfile_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.load_npz(\"X_train.npz\")\n",
    "t_train = np.load(\"t_train.npy\")\n",
    "train_ids = np.load(\"train_ids.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3086, 29813)\n",
      "(3086,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print train_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sparse.load_npz(\"X_test.npz\")\n",
    "test_ids = np.load(\"test_ids.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3724, 29813)\n",
      "(3724,)\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape\n",
    "print test_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.zeros((len(t_train),len(util.malware_classes)))\n",
    "y_train[np.arange(len(t_train)), t_train] = 1\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_bkup = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_bkup = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_bkup\n",
    "X_test = X_test_bkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 12 10 ..., 13 10 10]\n"
     ]
    }
   ],
   "source": [
    "print t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.116657+0.00914223\ttest-merror:0.129954+0.0238309\n",
      "[1]\ttrain-merror:0.125811+0.0201362\ttest-merror:0.15101+0.0241221\n",
      "[2]\ttrain-merror:0.0827126+0.0035979\ttest-merror:0.118284+0.0194618\n",
      "[3]\ttrain-merror:0.0753406+0.00615803\ttest-merror:0.113747+0.0157347\n",
      "[4]\ttrain-merror:0.067483+0.00854467\ttest-merror:0.112774+0.0149518\n",
      "[5]\ttrain-merror:0.0603542+0.00828676\ttest-merror:0.111155+0.0151997\n",
      "[6]\ttrain-merror:0.0531434+0.00680629\ttest-merror:0.108885+0.0160606\n",
      "[7]\ttrain-merror:0.0468246+0.00629489\ttest-merror:0.108562+0.0149649\n",
      "[8]\ttrain-merror:0.0435032+0.00553464\ttest-merror:0.105645+0.0126147\n",
      "[9]\ttrain-merror:0.0391282+0.0052149\ttest-merror:0.10856+0.0112754\n",
      "[10]\ttrain-merror:0.036941+0.00490272\ttest-merror:0.107264+0.010216\n",
      "[11]\ttrain-merror:0.0353208+0.00490988\ttest-merror:0.104023+0.0111452\n",
      "[12]\ttrain-merror:0.0326476+0.00392488\ttest-merror:0.105968+0.0113001\n",
      "[13]\ttrain-merror:0.0307844+0.00328253\ttest-merror:0.106615+0.0113321\n",
      "[14]\ttrain-merror:0.028597+0.00272009\ttest-merror:0.102726+0.0111982\n",
      "[15]\ttrain-merror:0.027139+0.0028321\ttest-merror:0.103699+0.0111727\n",
      "[16]\ttrain-merror:0.0254376+0.00317489\ttest-merror:0.104671+0.0111092\n",
      "[17]\ttrain-merror:0.0236552+0.00328777\ttest-merror:0.102079+0.0111248\n",
      "[18]\ttrain-merror:0.022602+0.00349831\ttest-merror:0.103375+0.0114263\n",
      "[19]\ttrain-merror:0.020901+0.00309218\ttest-merror:0.102727+0.0121036\n",
      "[20]\ttrain-merror:0.0192806+0.00256973\ttest-merror:0.103699+0.0129579\n",
      "[21]\ttrain-merror:0.0186324+0.00285191\ttest-merror:0.104347+0.0121044\n",
      "[22]\ttrain-merror:0.0175794+0.0023554\ttest-merror:0.104672+0.0127833\n",
      "[23]\ttrain-merror:0.0165262+0.00216398\ttest-merror:0.103699+0.0119455\n",
      "[24]\ttrain-merror:0.0159592+0.00202629\ttest-merror:0.104023+0.0128936\n",
      "[25]\ttrain-merror:0.0154732+0.00160744\ttest-merror:0.102727+0.0109167\n",
      "[26]\ttrain-merror:0.0149062+0.00152439\ttest-merror:0.103699+0.0116367\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'multi:softprob', 'num_class':15 }\n",
    "dtrain = xgb.DMatrix(X_train, label = t_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "cv = xgb.cv(param, dtrain, 999, nfold=5, early_stopping_rounds=10, verbose_eval=1)\n",
    "# make prediction\n",
    "# preds = bst.predict(dtest)\n",
    "# print preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions...\n"
     ]
    }
   ],
   "source": [
    "print \"making predictions...\"\n",
    "results = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11691f050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(results, bins=15, normed = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test params: 2, 2, 0.05, 1, 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanxu/anaconda2/envs/my-rdkit-env/lib/python2.7/site-packages/ipykernel_launcher.py:18: FutureWarning: 'argmin' is deprecated. Use 'idxmin' instead. The behavior of 'argmin' will be corrected to return the positional minimum in the future. Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest-merror 0.116666 for 29 rounds\n",
      "Test params: 2, 2, 0.05, 1, 1\n",
      "\ttest-merror 0.1085652 for 116 rounds\n",
      "Test params: 2, 2, 0.05, 2, 0.5\n",
      "\ttest-merror 0.1046756 for 132 rounds\n",
      "Test params: 2, 2, 0.05, 2, 1\n",
      "\ttest-merror 0.1182866 for 17 rounds\n",
      "Test params: 2, 2, 0.1, 1, 0.5\n",
      "\ttest-merror 0.1004634 for 87 rounds\n",
      "Test params: 2, 2, 0.1, 1, 1\n",
      "\ttest-merror 0.1030542 for 95 rounds\n",
      "Test params: 2, 2, 0.1, 2, 0.5\n",
      "\ttest-merror 0.1017588 for 100 rounds\n",
      "Test params: 2, 2, 0.1, 2, 1\n",
      "\ttest-merror 0.1150464 for 27 rounds\n",
      "Test params: 2, 2, 0.15, 1, 0.5\n",
      "\ttest-merror 0.1007872 for 66 rounds\n",
      "Test params: 2, 2, 0.15, 1, 1\n",
      "\ttest-merror 0.1011102 for 85 rounds\n",
      "Test params: 2, 2, 0.15, 2, 0.5\n",
      "\ttest-merror 0.1166668 for 11 rounds\n",
      "Test params: 2, 2, 0.15, 2, 1\n",
      "\ttest-merror 0.0998146 for 93 rounds\n",
      "Test params: 2, 2, 0.2, 1, 0.5\n",
      "\ttest-merror 0.1017596 for 38 rounds\n",
      "Test params: 2, 2, 0.2, 1, 1\n",
      "\ttest-merror 0.1001388 for 75 rounds\n",
      "Test params: 2, 2, 0.2, 2, 0.5\n",
      "\ttest-merror 0.0962486 for 74 rounds\n",
      "Test params: 2, 2, 0.2, 2, 1\n",
      "\ttest-merror 0.0972226 for 82 rounds\n",
      "Test params: 2, 4, 0.05, 1, 0.5\n",
      "\ttest-merror 0.1049984 for 31 rounds\n",
      "Test params: 2, 4, 0.05, 1, 1\n",
      "\ttest-merror 0.1066198 for 34 rounds\n",
      "Test params: 2, 4, 0.05, 2, 0.5\n",
      "\ttest-merror 0.0981958 for 108 rounds\n",
      "Test params: 2, 4, 0.05, 2, 1\n",
      "\ttest-merror 0.105648 for 64 rounds\n",
      "Test params: 2, 4, 0.1, 1, 0.5\n",
      "\ttest-merror 0.093983 for 68 rounds\n",
      "Test params: 2, 4, 0.1, 1, 1\n",
      "\ttest-merror 0.0975456 for 42 rounds\n",
      "Test params: 2, 4, 0.1, 2, 0.5\n",
      "\ttest-merror 0.100463 for 44 rounds\n",
      "Test params: 2, 4, 0.1, 2, 1\n",
      "\ttest-merror 0.0965744 for 65 rounds\n",
      "Test params: 2, 4, 0.15, 1, 0.5\n",
      "\ttest-merror 0.0933316 for 49 rounds\n",
      "Test params: 2, 4, 0.15, 1, 1\n",
      "\ttest-merror 0.0962502 for 40 rounds\n",
      "Test params: 2, 4, 0.15, 2, 0.5\n",
      "\ttest-merror 0.094306 for 54 rounds\n",
      "Test params: 2, 4, 0.15, 2, 1\n",
      "\ttest-merror 0.0949542 for 41 rounds\n",
      "Test params: 2, 4, 0.2, 1, 0.5\n",
      "\ttest-merror 0.0952776 for 24 rounds\n",
      "Test params: 2, 4, 0.2, 1, 1\n",
      "\ttest-merror 0.0956006 for 31 rounds\n",
      "Test params: 2, 4, 0.2, 2, 0.5\n",
      "\ttest-merror 0.0985182 for 34 rounds\n",
      "Test params: 2, 4, 0.2, 2, 1\n",
      "\ttest-merror 0.0981946 for 28 rounds\n",
      "Test params: 2, 6, 0.05, 1, 0.5\n",
      "\ttest-merror 0.1014342 for 30 rounds\n",
      "Test params: 2, 6, 0.05, 1, 1\n",
      "\ttest-merror 0.1040268 for 20 rounds\n",
      "Test params: 2, 6, 0.05, 2, 0.5\n",
      "\ttest-merror 0.1040276 for 39 rounds\n",
      "Test params: 2, 6, 0.05, 2, 1\n",
      "\ttest-merror 0.1014362 for 58 rounds\n",
      "Test params: 2, 6, 0.1, 1, 0.5\n",
      "\ttest-merror 0.0956018 for 59 rounds\n",
      "Test params: 2, 6, 0.1, 1, 1\n",
      "\ttest-merror 0.095602 for 40 rounds\n",
      "Test params: 2, 6, 0.1, 2, 0.5\n",
      "\ttest-merror 0.0985198 for 40 rounds\n",
      "Test params: 2, 6, 0.1, 2, 1\n",
      "\ttest-merror 0.103704 for 18 rounds\n",
      "Test params: 2, 6, 0.15, 1, 0.5\n",
      "\ttest-merror 0.0965732 for 30 rounds\n",
      "Test params: 2, 6, 0.15, 1, 1\n",
      "\ttest-merror 0.0949526 for 31 rounds\n",
      "Test params: 2, 6, 0.15, 2, 0.5\n",
      "\ttest-merror 0.0975456 for 33 rounds\n",
      "Test params: 2, 6, 0.15, 2, 1\n",
      "\ttest-merror 0.1017588 for 25 rounds\n",
      "Test params: 2, 6, 0.2, 1, 0.5\n",
      "\ttest-merror 0.0962482 for 21 rounds\n",
      "Test params: 2, 6, 0.2, 1, 1\n",
      "\ttest-merror 0.093334 for 25 rounds\n",
      "Test params: 2, 6, 0.2, 2, 0.5\n",
      "\ttest-merror 0.097548 for 36 rounds\n",
      "Test params: 2, 6, 0.2, 2, 1\n",
      "\ttest-merror 0.097222 for 39 rounds\n",
      "Test params: 6, 2, 0.05, 1, 0.5\n",
      "\ttest-merror 0.116666 for 29 rounds\n",
      "Test params: 2, 2, 0.05, 1, 1\n",
      "\ttest-merror 0.1085652 for 116 rounds\n",
      "Test params: 2, 2, 0.05, 2, 0.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-f47408f9405e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test-merror-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mboost_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test-merror-mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fanxu/anaconda2/envs/my-rdkit-env/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fanxu/anaconda2/envs/my-rdkit-env/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, iteration, feval)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;34m\"\"\"\"Evaluate the CVPack for one iteration.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fanxu/anaconda2/envs/my-rdkit-env/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected string, got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[0mdmats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fanxu/anaconda2/envs/my-rdkit-env/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0;31m# Booster can't accept data with different feature names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1273\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1274\u001b[0m                 \u001b[0mdat_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m                 \u001b[0mmy_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fanxu/anaconda2/envs/my-rdkit-env/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mfeature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'f{0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mean = 1\n",
    "min_mean = 1\n",
    "\n",
    "for num_round in [2,6,10]:\n",
    "    for max_depth in [2, 4, 6]:\n",
    "        for eta in np.arange(0.05, 0.25, 0.05):\n",
    "            for min_child_weight in [1, 2]:\n",
    "                for col_sample in [0.5, 1]:\n",
    "                    print(\"Test params: {}, {}, {}, {}, {}\".format(num_round, max_depth, eta, min_child_weight, col_sample))\n",
    "                    param = {'max_depth':max_depth, 'eta':eta, 'min_child_weight':min_child_weight, 'colsample_bytree':col_sample, 'objective':'multi:softprob', 'num_class':15 }\n",
    "                    dtrain = xgb.DMatrix(X_train, label = t_train)\n",
    "                    dtest = xgb.DMatrix(X_test)\n",
    "                    # num_round = 2\n",
    "                    bst = xgb.train(param, dtrain, num_round)\n",
    "                    \n",
    "                    cv = xgb.cv(param, dtrain, 999, nfold=5, early_stopping_rounds=10)\n",
    "                    mean = cv['test-merror-mean'].min()\n",
    "                    boost_rounds = cv['test-merror-mean'].argmin()\n",
    "                    print(\"\\ttest-merror {} for {} rounds\".format(mean, boost_rounds))\n",
    "    \n",
    "                    if mean < min_mean:\n",
    "                        min_mean = mean\n",
    "                        best_params = (num_round,max_depth,eta,min_child_weight,col_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params: {}, {}, {}, {}, {}, min_mean: {}\".format(best_params[0], best_params[1], best_params[2], best_params[3], best_params[4], min_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test params: 2, 6, 0.2, 1, 1\n",
    "\ttest-merror 0.093334 for 25 rounds    >>>>> 0.811xx\n",
    "Test params: 2, 4, 0.15, 1, 0.5\n",
    "\ttest-merror 0.0933316 for 49 rounds   >>>>> 0.82158\n",
    "Test params: 2, 4, 0.1, 1, 0.5\n",
    "\ttest-merror 0.093983 for 68 rounds    >>>> 0.825xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth':4, 'eta':0.1, 'min_child_weight':1, 'col_sample':0.5, 'objective':'multi:softprob', 'num_class':15 }\n",
    "dtrain = xgb.DMatrix(X_train, label = t_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "num_round = 200\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "# cv = xgb.cv(param, dtrain, 999, nfold=5, early_stopping_rounds=10, verbose_eval=1)\n",
    "# make prediction\n",
    "preds = bst.predict(dtest)\n",
    "# print preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions...\n"
     ]
    }
   ],
   "source": [
    "print \"making predictions...\"\n",
    "results = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 12 10 ..., 13 10 10]\n"
     ]
    }
   ],
   "source": [
    "print t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordered boost.csv and wrote to boost_200_4_01_1_05.csv\n"
     ]
    }
   ],
   "source": [
    "util.write_predictions(results, test_ids, \"boost.csv\")\n",
    "reorder_submission(\"boost.csv\", \"boost_200_4_01_1_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = sparse.load_npz(\"X_train.npz\")\n",
    "t_train = np.load(\"t_train.npy\")\n",
    "train_ids = np.load(\"train_ids.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3724, 29813)\n"
     ]
    }
   ],
   "source": [
    "X_test = sparse.load_npz(\"X_test.npz\")\n",
    "test_ids = np.load(\"test_ids.npy\")\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3724, 29813)\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X_train1, label = t_train)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.todense()\n",
    "#X_test = X_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_class': 15, 'min_child_weight': 1, 'eta': 0.15, 'objective': 'multi:softprob', 'colsample_bytree': 0.5, 'max_depth': 4}\n",
      "0\n",
      "(3724, 29813)\n",
      "(2308, 29813)\n",
      "(778, 29813)\n",
      "(3086,)\n",
      "(2308,)\n",
      "1\n",
      "(3724, 29813)\n",
      "(2314, 29813)\n",
      "(772, 29813)\n",
      "(3086,)\n",
      "(2314,)\n",
      "2\n",
      "(3724, 29813)\n",
      "(2317, 29813)\n",
      "(769, 29813)\n",
      "(3086,)\n",
      "(2317,)\n",
      "3\n",
      "(3724, 29813)\n",
      "(2319, 29813)\n",
      "(767, 29813)\n",
      "(3086,)\n",
      "(2319,)\n",
      "[10  8  8 ...,  0  0  0]\n",
      "Reordered boost.csv and wrote to semi_boost_70_4_015_1_05.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold as KFold\n",
    "import pandas as pd\n",
    "params = [{'max_depth':4, 'eta': 0.15, 'min_child_weight':1, 'colsample_bytree':0.5, 'objective':'multi:softprob', 'num_class':15 }]\n",
    "\n",
    "for param in params:\n",
    "    print param\n",
    "    labels = t_train\n",
    "    bst = xgb.train(param, dtrain, 70)\n",
    "    preds = bst.predict(dtest)\n",
    "    labels_test = np.argmax(preds, axis=1)\n",
    "    \n",
    "    \n",
    "    kf = KFold(t_train, n_folds=4)\n",
    "    \n",
    "    X = X_train1\n",
    "    stack_train = np.zeros((test_ids.shape[0],15)) # 15 classes.\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print i\n",
    "        print X_test.shape\n",
    "        X_train_ = X_test[train_fold,:]   \n",
    "        X_validate_ = X_test[validate,:]\n",
    "        labels_train_ = labels_test[train_fold]\n",
    "        labels_validate_ = labels_test[validate]\n",
    "        \n",
    "        print X_train_.shape\n",
    "        print X_validate_.shape\n",
    "        X_train_ = sparse.vstack((X, X_train_))\n",
    "        print labels.shape\n",
    "        print labels_train_.shape\n",
    "        labels_train_ = np.concatenate((labels, labels_train_))\n",
    "        # clf.fit(X_train,labels_train)\n",
    "        \n",
    "        dtrain_ = xgb.DMatrix(X_train_, label = labels_train_)\n",
    "        bst = xgb.train(param, dtrain_, 70)\n",
    "        dtest_ = xgb.DMatrix(X_validate_)\n",
    "        stack_train[validate] = bst.predict(dtest_)\n",
    "\n",
    "    results = np.argmax(stack_train, axis=1)\n",
    "    print results\n",
    "    util.write_predictions(results, test_ids, \"boost.csv\")\n",
    "    reorder_submission(\"boost.csv\", \"semi_boost_70_4_015_1_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2f468710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(results,bins=15, normed = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AttributeError: \"'Booster' object has no attribute 'handle'\" in <bound method Booster.__del__ of <xgboost.core.Booster object at 0x1a257a9410>> ignored\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-764a1c34c92d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlabels_validate_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mlabels_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold as KFold\n",
    "import pandas as pd\n",
    "params = [{'max_depth':4, 'eta': 0.15, 'min_child_weight':1, 'colsample_bytree':0.5, 'objective':'multi:softprob', 'num_class':15 }]\n",
    "\n",
    "for param in params:\n",
    "    X = pd.DataFrame(X_train)\n",
    "    X['label'] = t_train.tolist()\n",
    "    # X = pd.merge(X, pd.t_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "\n",
    "    labels = t_train\n",
    "    bst = xgb.train(param, dtrain, 70)\n",
    "    preds = bst.predict(dtest)\n",
    "    labels_test = np.argmax(preds, axis=1)\n",
    "    \n",
    "    X_test['label'] = labels_test.tolist()\n",
    "    # X_test = pd.merge(X_test, labels_test)\n",
    "    \n",
    "    kf = KFold(t_train, n_folds=10)\n",
    "    X = X.as_matrix()\n",
    "    X_test = X_test.as_matrix()\n",
    "    \n",
    "    stack_train = np.zeros((test_ids.shape[0],15)) # 15 classes.\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print i\n",
    "        X_train_ = X_test[train_fold,:]   \n",
    "        X_validate_ = X_test[validate,:]\n",
    "        labels_train_ = labels_test[train_fold]\n",
    "        labels_validate_ = labels_test[validate]\n",
    "        \n",
    "        X_train = np.concatenate((X, X_train))\n",
    "        labels_train = np.concatenate((labels, labels_train))\n",
    "        clf.fit(X_train,labels_train)\n",
    "        stack_train[validate] = clf.predict_proba(X_validate)\n",
    "\n",
    "    results = np.argmax(stack_train, axis=1)\n",
    "    print results\n",
    "    util.write_predictions(results, test_ids, \"boost.csv\")\n",
    "    reorder_submission(\"boost.csv\", \"semi_boost_70_4_015_1_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 29813\tAccuracy: 0.85839 (+/- 0.02575)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(n_estimators = 1000, n_jobs = -1, class_weight = \"balanced\")\n",
    "RF.fit(X_train, y_train)\n",
    "scores = cross_val_score(RF, X_train, y_train, cv=5)\n",
    "print \"Features: \" + str(RF.n_features_) + (\"\\tAccuracy: %0.5f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))\n",
    "RF_best = RF\n",
    "score_best = scores.mean()\n",
    "X_train_best = X_train\n",
    "X_test_best = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 5222\tAccuracy: 0.86260 (+/- 0.02325)\n",
      "Features: 1779\tAccuracy: 0.86131 (+/- 0.02374)\n",
      "Features: 951\tAccuracy: 0.86163 (+/- 0.02617)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "while X_train.shape[1] > 1000:\n",
    "    model = SelectFromModel(RF, prefit=True, threshold = \"0.5*mean\")\n",
    "    X_train = model.transform(X_train)\n",
    "    ## trick: break if we didn't remove any feature\n",
    "    if X_train.shape[1] == X_test.shape[1]:\n",
    "        break\n",
    "    X_test = model.transform(X_test)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators = 1000, n_jobs = -1, class_weight = \"balanced\")\n",
    "    RF.fit(X_train, y_train)\n",
    "    scores = cross_val_score(RF, X_train, y_train, cv=5)\n",
    "    mean_score = scores.mean()\n",
    "    print \"Features: \" + str(RF.n_features_) + (\"\\tAccuracy: %0.5f (+/- %0.5f)\" % (mean_score, scores.std() * 2))\n",
    "    \n",
    "    if score_best <= mean_score:\n",
    "        del X_train_best\n",
    "        del X_test_best\n",
    "        RF_best = RF\n",
    "        score_best = mean_score\n",
    "        X_train_best = X_train\n",
    "        X_test_best = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "sqrt\n",
      "None\n",
      "\tAccuracy: 0.87719 (+/- 0.02433)\n",
      "200\n",
      "sqrt\n",
      "balanced\n",
      "\tAccuracy: 0.86423 (+/- 0.02333)\n",
      "200\n",
      "log2\n",
      "None\n",
      "\tAccuracy: 0.87330 (+/- 0.02515)\n",
      "200\n",
      "log2\n",
      "balanced\n",
      "\tAccuracy: 0.86293 (+/- 0.02551)\n",
      "200\n",
      "None\n",
      "None\n",
      "\tAccuracy: 0.88172 (+/- 0.01893)\n",
      "200\n",
      "None\n",
      "balanced\n",
      "\tAccuracy: 0.86131 (+/- 0.03184)\n",
      "600\n",
      "sqrt\n",
      "None\n",
      "\tAccuracy: 0.87686 (+/- 0.02268)\n",
      "600\n",
      "sqrt\n",
      "balanced\n",
      "\tAccuracy: 0.86196 (+/- 0.02475)\n",
      "600\n",
      "log2\n",
      "None\n",
      "\tAccuracy: 0.87394 (+/- 0.02433)\n",
      "600\n",
      "log2\n",
      "balanced\n",
      "\tAccuracy: 0.86066 (+/- 0.02461)\n",
      "600\n",
      "None\n",
      "None\n",
      "\tAccuracy: 0.88172 (+/- 0.01752)\n",
      "600\n",
      "None\n",
      "balanced\n",
      "\tAccuracy: 0.86163 (+/- 0.03144)\n",
      "1000\n",
      "sqrt\n",
      "None\n",
      "\tAccuracy: 0.87654 (+/- 0.02416)\n",
      "1000\n",
      "sqrt\n",
      "balanced\n",
      "\tAccuracy: 0.86293 (+/- 0.02449)\n"
     ]
    }
   ],
   "source": [
    "for n in [200, 600, 1000, 1400]:\n",
    "    for f in ['sqrt', 'log2', None]:\n",
    "        for c in [None, \"balanced\"]:\n",
    "            RF = RandomForestClassifier(n_estimators = n, n_jobs = -1, max_features = f, class_weight = c)\n",
    "            RF.fit(X_train_best, y_train)\n",
    "            scores = cross_val_score(RF, X_train_best, y_train, cv=5)\n",
    "            mean_score = scores.mean()\n",
    "            print str(n)\n",
    "            print f\n",
    "            print c\n",
    "            print (\"\\tAccuracy: %0.5f (+/- %0.5f)\" % (mean_score, scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions...\n",
      "writing predictions...\n",
      "Reordered test.csv and wrote to experiment_rf_results.csv\n"
     ]
    }
   ],
   "source": [
    "# TODO make predictions on text data and write them out\n",
    "print \"making predictions...\"\n",
    "results = np.argmax(preds, axis=1)\n",
    "\n",
    "print \"writing predictions...\"\n",
    "util.write_predictions(results, test_ids, \"test.csv\")\n",
    "\n",
    "reorder_submission(\"test.csv\", \"experiment_rf_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_bkup\n",
    "X_test = X_test_bkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(n_estimators = 1000, n_jobs = -1)\n",
    "RF.fit(X_train, y_train)\n",
    "scores = cross_val_score(RF, X_train, y_train, cv=5)\n",
    "print \"Features: \" + str(RF.n_features_) + (\"\\tAccuracy: %0.5f (+/- %0.5f)\" % (scores.mean(), scores.std() * 2))\n",
    "RF_best2 = RF\n",
    "score_best2 = scores.mean()\n",
    "X_train_best2 = X_train\n",
    "X_test_best2 = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "while X_train.shape[1] > 1000:\n",
    "    model = SelectFromModel(RF, prefit=True, threshold = \"0.5*mean\")\n",
    "    X_train = model.transform(X_train)\n",
    "    ## trick: break if we didn't remove any feature\n",
    "    if X_train.shape[1] == X_test.shape[1]:\n",
    "        break\n",
    "    X_test = model.transform(X_test)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators = 1000, n_jobs = -1)\n",
    "    RF.fit(X_train, y_train)\n",
    "    scores = cross_val_score(RF, X_train, y_train, cv=5)\n",
    "    mean_score = scores.mean()\n",
    "    print \"Features: \" + str(RF.n_features_) + (\"\\tAccuracy: %0.5f (+/- %0.5f)\" % (mean_score, scores.std() * 2))\n",
    "    \n",
    "    if score_best2 <= mean_score:\n",
    "        del X_train_best2\n",
    "        del X_test_best2\n",
    "        RF_best2 = RF\n",
    "        score_best2 = mean_score\n",
    "        X_train_best2 = X_train\n",
    "        X_test_best2 = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
